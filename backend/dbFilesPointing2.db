{"file":{"nodeType":1,"tagName":"div","attributes":[["id","content"],["class","document"]],"childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"\n\n\n  "},{"nodeType":1,"tagName":"meta"},{"nodeType":3,"nodeName":"#text","nodeValue":"\n  "},{"nodeType":1,"tagName":"meta","attributes":[["name","generator"],["content","pandoc"]]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n  "},{"nodeType":1,"tagName":"meta","attributes":[["name","viewport"],["content","width=device-width, initial-scale=1.0, user-scalable=yes"]]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n  "},{"nodeType":1,"tagName":"title","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"US20150330429A1"}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n  "},{"nodeType":1,"tagName":"style","attributes":[["type","text/css"]],"childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"\n      code{white-space: pre-wrap;}\n      span.smallcaps{font-variant: small-caps;}\n      span.underline{text-decoration: underline;}\n      div.column{display: inline-block; vertical-align: top; width: 50%;}\n  "}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n  "},{"nodeType":8,"nodeName":"#comment","nodeValue":"[if lt IE 9]>\n    <script src=\"//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js\"></script>\n  <![endif]"},{"nodeType":3,"nodeName":"#text","nodeValue":"\n\n\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Drag-and-Pop and Drag-and-Pick: techniques for accessing remote screen content on touch- and pen-operated systems"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"ABSTRACT"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Drag-and-pop and drag-and-pick are interaction techniques designed for users of pen- and touchoperated display systems. They provide users with access to screen content that would otherwise be impossible or hard to reach, e.g., because it is located behind a bezel or far away from the user. Drag-and-pop is an extension of traditional drag-and-drop. As the user starts dragging an icon towards some target icon, drag-and-pop responds by temporarily moving potential target icons towards the user’s current cursor location, thereby allowing the user to interact with these icons using comparably small hand movements. Drag-and-Pick extends the drag-and-pop interaction style such that it allows activating icons, e.g., to open folders or launch applications. In this paper, we report the results of a user study comparing drag-and-pop with traditional drag-and-drop on a 15’ (4.50m) wide interactive display wall. Participants where able to file icons up to 3.7 times faster when using the drag-and-pop interface."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Keywords"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Drag-and-drop, drag-and-pick, interaction technique, pen input, touchscreen, heterogeneous display."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Introduction"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"With the emergence of pen- and touch-operated personal digital assistants (PDAs), tablet computers, and wall-size displays (e.g., Liveboard, Elrod et al., 1992; Smartboard, http://www.smarttech.com), touch and pen input have gained popularity. Over the past years, more complex display systems have been created by combining multiple such display units. Wall-size touch displays have been combined into display walls, such as the DynaWall (Streitz 2001), or the iRoom Smartboard wall (Johanson, 2002b). Recent PDAs and tablet computers allow connecting additional displays, such as another tablet or a monitor in order to extend the device’s internal display space."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Touch/pen-operated screens that consist of multiple display units bring up a new class of input challenges that cannot always be solved with existing techniques, because many of the existing techniques were designed for indirect input devices, such as mice, track pads, or joysticks. Indirect input devices can be used on arbitrary display configurations, because they can simply be mapped to the respective topology (e.g., PointRight, Johanson 2002a). Touch/ pen input, however, is based on the immediate correspondence between input space and display space and thus requires users to adapt their input behavior to the physicality of the display system. Here are three examples where this can become problematic."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/DaP1.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Scenario 1: External monitors. One or more display units within a display system may not be equipped with a touch or pen sensor. Connecting an external monitor to a tablet computer or PDA, for example, allows users to see more material, but requires them to use an indirect input device, such as a mouse, when interacting with content on the external monitor. Since some tablet-specific tasks, such as scribbling, are hard to accomplish with a mouse, users find themselves continuously switching between pen and mouse."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Scenario 2: Interactions across display units. Some interaction techniques, such as drag-and-drop, require users to interact with two or more icons in a single pen-down interaction. If these icons are distributed across physically separate pen/touch input display units, users first have to bring all involved icons to the same display unit, a potentially timeconsuming activity (Figure 2a-c)."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Scenario 3: Bridging long distances. Accessing icons located far away from the user, e.g., on the opposite side of a 15’ DynaWall, requires users to physically walk over, the time for which may in some circumstances increase linearly with distance (Guiard et at, 2001). In addition, drag interactions get more error-prone with distance, because users drop objects accidentally when failing to continuously keep the pen tip in contact with the display surface (Rekimoto 1997)."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Drag-and-pop & drag-and-pick"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Drag-and-pop and drag-and-pick are interaction techniques that address these issues. We will begin by giving an overview; more detailed descriptions of both techniques can be found in Section 4"}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Drag-and-pop"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"extends traditional drag-and-drop as illustrated by Figure 1. (a) The user intends to delete a Word memo by dragging it into the recycle bin. (b) As the user starts dragging the memo’s icon towards the recycle bin, icons that are of compatible type and located in the direction of the user’s drag motion “pop up”. This means that for each of these icons a link icon is created (tip icon) that appears in front of the user’s cursor. Tip icons are connected to the original icon (base icon) using a rubber band. (c) The user drags the memo over the recycle bin and releases the mouse button. The recycle bin accepts the memo. Alternatively, the user could have dropped the memo over the word processor or the web browser icon, which would have launched the respective application with the memo. (d) When the user drops the icon, all tip icons disappear instantly. Figure 2d shows how drag-and-pop simplifies dropping icons onto targets located at the other side"}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/DaP2.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Drag-and-pick"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["style","background-color: yellow;"]],"childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"modifies the drag-and-pop interaction concept such that it allows activating icons, e.g., to open a folder or to launch a program. While drag-and-pop is initiated by the user dragging an icon, drag-and-pick starts with the user performing a drag interaction on empty screen space. The system’s response to this drag interaction is similar to drag-and-pop, but with two differences. First, all icons located in the direction of the drag motion will pop up, not only those of compatible type (Figure 3). Second, as the user drags the mouse cursor over one of the targets and releases the mouse button, the folder, file, or application associated with the icon is activated as if it had been double clicked. Figure 4 shows how this allows users to use the pen for launching an application, the icon of which is located on a monitor not supporting pen input. In principle, drag-and-pick can be applied to any type of widget, e.g., any buttons and menus located on a non-pen accessible monitor. In this paper, however, we will focus on the manipulation of icons."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Related Work"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Drag-and-drop is a well-know interaction technique for transferring or copying information using a pointing device, while avoiding the use of a hidden clipboard (Wagner, 1995; Beaudouin-Lafon, 2000). Hyperdragging (Rekimoto, 1999), allows extending drag-and-drop across physically separate displays (Scenario 2), but requires an indirect input device, such as a mouse. Most techniques compatible with pen usage are based on point-and-click, e.g., pickand- drop (Rekimoto, 1997) and take-and-put (Streitz et al., 2001). These techniques, however, cannot be used to access material on a display unit not providing pen support (Scenario 1)."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/DaP3.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/DaP4.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"A different set of interaction techniques have been proposed to help users overcome large distances (Scenario 3). Manual And Gaze Input Cascaded (MAGIC) pointing (Zhai et al., 1999) uses eye tracking to move the cursor to the target area, from where the user guides the cursor manually (which requires an indirect input device). Gesture input techniques allow selecting a target and a command in a single interaction and are generally compatible with pen input (Rubine, 1991). ‘Throwing’ allows users to accelerate an object with a small gesture; the object then continues its trajectory based on its inertia (Gei ler, 1998). The imprecision of human motor skills has prevented throwing from being used for reliable target acquisition. Myers et al. (2002) used laser pointers to acquire targets on a Smartboard, but found them to be slower than touch input. A variety of mouse-based interaction techniques use destination prediction to simplify navigation (e.g., Jul, 2002). Dulberg et al. (1999) proposed a flying click or flick for snapping the mouse to target locations. Swaminathan and Sato (1997) proposed making relevant controls on the screen “sticky”. As an alternative way of launching applications, today’s operating systems offer menus containing lists of available application or documents. A ‘send to’ option (Microsoft Windows) allows sending an icon to a target selected from a predefined list. Compared to 2D desktops, which typically use a larger amount of screen space than pull-down or pop-up menus, menus are limited to a smaller selection of choices unless they use a hierarchical menu organization, which makes their usage less transparent and often less efficient. Furthermore, invoking a content-menu may require hitting a qualifier key, which can be problematic on touch-based systems."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Design and Algorithms"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"In this section, we will take a more detailed look at the design and algorithms behind drag-and-pop/pick. 4.1 Selecting candidates In order to reduce clutter, drag-and-pop creates tip icons only for a subset of the icons on the screen. Drag-and-pop’s candidate selection algorithm is initialized with the entire set of icons on the screen; it then successively eliminates candidates using the following four rules. First, icons of incompatible type are eliminated. If the user drags a text file, the icon of a text processor can create a tip icon; the recycle bin icon can create a tip icon; the icon of another text file, however, cannot, because dragging two text files onto each other is usually not associated with any behavior. Drag-and-pick bypasses this selection step in order to allow users to activate any type of icon. Second, icons located between the cursor and the location where the tip icons cluster will appear (see following section) are eliminated. This rule avoids creating tip icons that move away from the cursor. Third, only icons that are located within a certain angle from the initial drag direction (the target sector) are considered. The initial drag direction is determined the moment the user drags an icon further than a given threshold (default 15 pixels). During preliminary testing on a Smartboard, we got good results with first-time users when using sector sizes of  30 to  45 degrees. The sector size could be reduced to sector sizes of  20 degrees as users gained more experience. Forth, if the number of qualifying icons is above some hard limit, drag-and-pop eliminates tip icon candidates until the hard limit is met. Icons are removed in an order starting at the outside of the target sector moving inwards. This rule assures the scalability of drag-and-pop to densely populated displays, but requires drag-and-pop users working with densely populated screens to aim more precisely. We typically use hard limits between 5 and 10."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Computing The Tip Icon Layout"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/DaP5.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Once tip icon candidates have been selected, dragand- pop determines where on the screen to place the tip icons. In order to avoid interference between tip icons, the location of all tip icons is computed in a centralized fashion. Our drag-and-pop prototype uses the following algorithm that is illustrated by Figure 5: (1) Snap icons to a grid and store them in a two-dimensional array, with each array element representing one cell of the grid. If two or more icons fall into the same cell, refine the grid. (2) Shrink the icon layout by eliminating all array columns and rows that contain no icons. (3) Translate icon positions back to 2D space by mapping the array onto a regular grid. By default, the output grid is chosen to be slightly tighter than the input grid, which gives extra compression."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"We chose this algorithm, because it preserves alignment, proximity, and spatial arrangement between icons, which allows users to use their spatial memory when identifying the desired target within the tip icon cluster. This is especially useful when tip icons look alike (e.g., a folder in a cluster of folders). In order to help users distinguish local icon clusters from surrounding icons more easily, the algorithm may be adjusted to shrink empty rows and columns during layout computation instead of removing them entirely."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["style","background-color: yellow;"]],"childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"After the tip icon layout has been computed, drag-and-pop positions it on the screen such that the center of the layout’s bounding box is located at the direct extension of the user’s current mouse motion. The distance of the tip icon cluster to the user’s current cursor position is configurable. For inexperienced users, we got best results with distances of around 100 pixels; shorter distances made these users likely to overshoot the cluster. For more experienced users, we were able to reduce the distance to values around 30 pixels, which allowed these users to operate drag-and-pop with less effort, in a more “menu-like” fashion. In order to reduce visual interference between tip icons and icons on the desktop, drag-and-pop diminishes desktop icons while tip icons are visible. This may obscure the nearby icons on the desktop making it hard to access to."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"The Rubber Band"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"When the tip icon cluster is displayed, users need to re-identify their targets within the tip icon cluster in order to be able to successfully acquire them. Our first implementation of drag-and-pop created tip icons on top of their bases and used slow-inslow- out animation (Shneiderman 1998) to move tip icons to their final location. While this approach allowed users to locate the final position of the desired tip icon by visually tracking it on its way from basis to final position, it also required users to either wait for the animation to complete or to acquire a moving target. We therefore chose to abandon the animation and immediately display tip icons at their final destinations. In lieu of the animation, we provided tip icons with rubber bands. The design prototype of the rubber band is shown in Figure 6. For performance reasons, our prototype, which is shown in all other screenshots, uses rubber bands of a lower level of graphical detail, i.e., a tape and three lines in the color scheme of the corresponding icon. The purpose of the rubber band is to offer the functionality of the animation, but without the problems alluded to above. The rubber band, decorated with the respective icon’s texture, can be thought of as having been created by taking a photograph of the tip icon animation with a very long shutter speed (so-called motion blur, e.g., Dachille and Kaufman, 2000). Like the animation, the rubber band allows users to trace the path from base to tip icon. However, users can do this at their own pace and the customized texturing of the rubber band allows users to start tracing it anywhere, not only at the base."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"The rubber band is provided with a narrow midriff section, suggesting that the rubber band is elastic. This design was chosen to help users understand that tip icons have retracted to their bases when they disappear at the end of the interaction. This feature may also help users find their way to the tip icon faster, because it provides users with a visual cue about how far away the tip icon is located. A thick rubber band section implies that the tip icon (or base) is close; a thin rubber band section indicates that the target is further away."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/DaP6.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Aborting Drag-and-Pop Interactions"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["style","background-color: yellow;"]],"childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"As soon as tip icons and rubber bands are shown on the screen, drag-and-pop waits for the user to acquire one of the tip icons to complete the ongoing drag-and-pop or drag-and-pick interaction. There are two cases, however, in which users will want to abort the interaction without acquiring a tip icon. The first case is when the user dragged the mouse at a wrong angle so that the desired target icon did not pop up. In this case, the user may either drop the icon and try again or complete the interaction as a regular drag-and-drop interaction, i.e., by dropping the icon onto the target icon’s base instead. The other case occurs if the user is intending to perform a regular mouse drag operation, for example to rearrange icons on the desktop or to capture a set of icons using a lasso operation. For these cases, drag-and-pop allows users to terminate tip icons onthe- fly and to complete the interaction without dragand- pop/pick. To abort, users have to move the mouse cursor away from the tip icon cluster while still keeping the mouse depressed. This can be done by overshooting the cluster or by changing mouse direction. In particular, this allows users to switch to the normal drag-and-drop and lasso-select functionality by introducing a simple zigzag gesture into their cursor path. The zigzag contains at least one motion segment moving away from the tip icons, thus terminating tip icons as soon as they appear. The algorithm: the tip icon cluster is kept alive as long as at least one of the following three rules is successful. The first rule checks whether the mouse cursor has moved closer to the center of at least one of the icons in the tip icon cluster. This rule makes sure that the cluster does not disappear while users approach their targets. The second rule checks if the cursor is in the direct vicinity of an icon. This rule provides tolerance against users overshooting a tip icon while acquiring it. The third and last rule keeps the cluster alive if the cursor is stationary or if it is moving backwards very slowly (up to 5 pxl/frame). This rule makes drag-and-pop insensitive to jitter. Figure 7 illustrates the resulting behavior."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/DaP7.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"User Study"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"In this section, we report the results of a user study comparing drag-and-pop with the traditional dragand- drop technique. To examine the effects of bezelcrossing as well as distance, as described in Scenarios 2 and 3, we chose to run the study on a tiled wall-size display. During the study, in which participants filed icons into folders or dragged them onto the icons of matching applications, we recorded the time and accuracy of these movements. Our main hypothesis was that participants would perform faster when using the drag-and-pop interface, primarily because it would avoid the need for crossing the bezels, but also because it would bridge the space to very distant icons more efficiently."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Desktop Layout"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"To obtain a representative set of icon arrangements for the study, we gathered desktop screenshots from 25 coworkers who volunteered their participation (15 single, 6 dual, and 4 triple monitor users). Overall resolutions ranged from 800,000 pixels to 3,900,000 pixels (66% more than the display wall used in the experiment)."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"We clustered the obtained desktops by number of icons and arrangement pattern. Then we chose representatives from each of the three resulting main clusters for the study (Figure 8). The “sparse” desktop reflected the desktops of roughly two thirds of the participants. It contained only 11 icons, most of which were lined up in the top left corner of the screen. The “frame” desktop reflected the desktops of three of the participants. It contained 28 icons arranged around the top, left, and right edge of the screen. The “cluttered” desktop, finally, contained 35 icons that were spread primarily across the top and left half of the screen. Five participants had chosen this style of arranging their icons. Icon layouts were stretched to fit the aspect ratio of the display wall used in the experiment. An area at the bottom right of the screen was reserved for the starting locations of the icons to be filed during the study (dashed shape in Figure 8)."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/DaP8.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Participants"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Eight colleagues with no experience using drag-andpop were recruited for this experiment. Due to technical problems, the data from one of these participants had to be dropped leaving us with 7. There were 2 female and 5 male participants ranging in age between 18 and 35. All were right handed with normal or corrected-to-normal vision."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Method"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"The test was run on the DynaWall (Streitz, 2001), a display wall consisting of three Smartboard units (Figure 9). Each Smartboard consisted of a backprojected 72”display with resistive touch input, so that the entire display was 15’ (4.50m) long and 45” (1.12m) high. Display units could be operated by touching the display, but for easier handling participants were provided with color-free felt pens. Each of the three display units ran at a resolution of 1024x768 pixels, offering an overall resolution of 3072x768 pixels. The three display units were connected to a single PC equipped with two Matrox Millennium graphics cards and running WindowsXP. During the experiment, the DynaWall ran a simulated Windows desktop. We compared dragand- pop to a control condition of drag-and-drop. Since our preliminary Windows-based version of drag-and-pop did not support the full functionality required for the study, we implemented a simulation using Macromedia Flash (www.macromedia.com). The drag-and-pop interface used in the experiment was configured to a  30 degree target sector, 35 pixel target distance, and a maximum number of 5 tip icons."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/DaP9.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"To each desktop layout we added 10 document icons in the lower right quadrant of the screen. These appeared in six different arrangements (Figure 8 shows 2 of them). The participants’ task was to drag these icons into a given target folder or application. Icons of image files, for example, were to be filed in a folder labeled “My Pictures” and all Word documents should be dropped onto the Word application. To counterbalance for order effects, we required participants to file the documents in a randomized order. That is, for each movement, the item to be filed was highlighted along with the target icon. All other document icons were frozen, so that participants could only move the highlighted icon. As soon as participants began moving an item, all highlighting was removed, forcing participants to remember the destination item. We did this to assure that participants would have to re-identify tip icons when using the drag-and-pop interface, just as they would in a real-world task."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Participants were allowed several minutes to practice moving and filing icons in the prototype to get them accustomed to both the DynaWall display and the drag-and-pop interface. Once it was clear that users understood how to use the display and the interfaces, they were allowed to go on to the study. Participants filed 2 sets of icons for each interface (drag-and-pop and control), for each of the three desktops. Thus participants filed 2 x 10 icons x 2 interface x 3 desktops for a total of 120 movements. To mitigate learning effects associated with new desktop arrangements or a new interface, we omitted the first 5 trials for any desktop-interface combination from our analyses, yielding ~15 correct trials per cell or 90 movements per participant."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Results"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Task Performance"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/DaP10.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Task performance was evaluated through speed and accuracy measurements. Error rates were considerably larger for drag-and-pop than for the control (6.7% vs. 1%). We observed two things that made this type of error more likely in the drag-and-pop condition. First, in the drag-and-pop condition candidate targets were brought closer together, making it easier to accidentally drop an item on the wrong target. Second, because drag-and-pop targets had been translated away from their “home” location, participants would sometimes forget which item was in fact the target, especially if visually similar icons (e.g., other folders) had created tip icons as well. All data analyses for movement times were performed on the median movement times for each participant in each condition to normalize the typical skewing associated with response time data. Summary statistics report the means of these times. Target icons could be located in the same display unit as the icon to be filed, in a neighbor display unit, or in the display unit at the other end of the display wall, requiring users to cross 0, 1, or 2 bezels in order to file the icon. To test the effect of bezel crossing on performance, we ran a 2 (Condition) x 3 (Bezels Crossed) within subjects ANOVA on the median movement data. This revealed a significant main effect for condition, F(1,6) = 18.2, p less than 0.01 Collapsed across all distances, drag-and-pop was significantly faster than the control. There was also a significant main effect of bezels crossed, F(2,12)=19.5, p less than 0.01; movement time increased as the number of bezels participants had to cross to get to the target icon increased. As hypothesized, we also saw a significant interaction between condition and number of bezels crossed, F(2,12)=15.2, p less than 0.01. As seen in Figure 10, an increase in the number of crossed bezels resulted in only a small increase in movement time for drag-and-pop, whereas it had a huge effect for the control interface. When no bezels had to be crossed, drag-and-pop appeared to be slightly slower than control, although follow-up t-tests showed that this difference was not significant, t(6)=1.73, ns. When 1 or 2 bezels had to be crossed, drag-and-pop was significantly faster than drag-and-drop (t(6)=4.02, p less than 0.01 & t(6)=4.12, p less than 0.01, respectively). With 1 bezel crossed, dragand- pop was twice as fast as the control and with 2 bezels it was 3.7 times as fast."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/DaP11.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Figure 11 shows a scatter plot of movement time versus target distance for both conditions. The best linear fit for drag-and-drop was f(x)=0.007x-1.76, r2=0.23. The linear fit for drag-and-pop was f(x)=4.19, r2 less than 0.0001. This reinforces what can be seen in Figure 10—movement time increases with distance for the control interface, but stays relatively constant for the drag-and-pop interface."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Questionnaire and Subjective Feedback"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["style","background-color: yellow;"]],"childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"At the end of the study, participants answered a short questionnaire about their experience using the DynaWall and drag-and-pop. Participants were very enthusiastic about drag-and-pop. On a 7 point Likert scale (where 7=strongly agree and 1=strongly disagree), there was a mean > 6 for questions such as, “I liked using drag-and-pop”, “I always understood what was happening when drag-and-pop was on,”and “I would use drag-and-pop for large displays.” There was a mean of less than 3 for “It took a long time to get used to drag-and-pop” and “It was hard to control what the targets did when drag-and-pop was on.” Participants reported the drag-and-pop interface to cause less manual stress and fatigue than the control interface. The most common problem with drag-and-pop was in getting the right group of targets to pop up, and several participants requested a wider angle for destination targets. This relates to an observation we made about how people interact with touch-sensitive wall-displays. On the wall display, participants had to employ their whole arm to make a movement, resulting in targeting motions in the shape of arcs. This means that the initial direction of the movement was not in the direction of the target. To accommodate such arcs in the future, we have adapted the target selection algorithm of drag-and-pop by giving the target sector extra tolerance for movements towards the top of the screen."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Conclusions and Future Work"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"The substantial time-savings found in the user study confirm our expectations. Although when used within a single screen unit drag-and-pop does not seem to by faster than traditional drag and drop (first pair of bars in Figure 10; drag-and-pop’s capability of bridging distance to the target seems to be nullified by the need for re-orientation), its advantages on very large screens and its capability of bridging across display units are apparent. On the usability side, we were glad to see that participants had no trouble learning how to use the technique and that they described the technique as understandable and predictable. The single biggest shortcoming, the target selection, is the subjects of current work. In addition to the changes described above, we consider dropping the notion of a fixed target sector size and replace it with a mechanism that adjusts the sector size dynamically based on the number of matching targets. Given the recent advent of commercially available tablet computers, our next step will be to explore how drag-and-pop and especially drag-andpick can help tablet computer users work with external monitors. While this paper focused on icons, we plan to explore ways of operating menus, sliders, and entire applications using the techniques described in this article."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n\n\n"}]},"fileName":"drag-and-pop.html","index":0,"_id":"s2k7f0cNQ6z2ZuQF"}
{"file":{"nodeType":1,"tagName":"div","attributes":[["id","content"],["class","document"]],"childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"\n\n\n  "},{"nodeType":1,"tagName":"meta"},{"nodeType":3,"nodeName":"#text","nodeValue":"\n  "},{"nodeType":1,"tagName":"meta","attributes":[["name","generator"],["content","pandoc"]]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n  "},{"nodeType":1,"tagName":"meta","attributes":[["name","viewport"],["content","width=device-width, initial-scale=1.0, user-scalable=yes"]]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n  "},{"nodeType":1,"tagName":"title","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"US20150330429A1"}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n  "},{"nodeType":1,"tagName":"style","attributes":[["type","text/css"]],"childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"\n      code{white-space: pre-wrap;}\n      span.smallcaps{font-variant: small-caps;}\n      span.underline{text-decoration: underline;}\n      div.column{display: inline-block; vertical-align: top; width: 50%;}\n  "}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n  "},{"nodeType":8,"nodeName":"#comment","nodeValue":"[if lt IE 9]>\n    <script src=\"//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js\"></script>\n  <![endif]"},{"nodeType":3,"nodeName":"#text","nodeValue":"\n\n\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Object Pointing: A Complement to Bitmap Pointing in GUIs"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"ABSTRACT"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Pointing has been conceptualized and implemented so far as the act of selecting pixels in bitmap displays. We show that the current technique, which we call bitmap pointing (BMP), is often sub-optimal as it requires continuous information from the mouse while the system often just needs the discrete specification of objects. The paper introduces object pointing (OP), a novel interaction technique based on a special screen cursor that skips empty spaces, thus drastically reducing the waste of input information. We report data from 1D and 2D Fitts’ law experiments showing that OP outperforms BMP and that the performance facilitation increases with the task’s index of difficulty. We discuss the implementation of OP in current interfaces. Key words: Input and Interaction Technologies, Pointing, Fitts’ law."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Introduction"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Since the advent, about two decades ago, of graphical user interfaces (GUIs), which led to the so-called WIMP paradigm (Windows, Icons, Menus, and Pointers) for human-computer interaction (HCI), sustained efforts have been made to optimize pointing, the key elemental act that permits selection among graphical objects such as icons, buttons, menu items, or hypertext links. HCI researchers realized only recently that interface designers can pursue a more ambitious goal than just making pointing to a graphical object as easy as pointing to a real-life object: the emerging challenge is to make pointing in GUIs easier than normal [4, 5, 8, 14, 17]. It has been known, from the beginning of the WIMP era [6] that target acquisition time (or movement time, MT) in GUIs is almost entirely determined by the ratio of target distance D and target width W, as stated by Fitts’ law [7, 15]: MT = a + b log2 (D/W +1), with a and b standing for empirically adjustable coefficients (b>0) and the expression log2(D/W +1) defining what Fitts termed the index of difficulty (ID). Equation 1 suggests two non-exclusive ways of facilitating target acquisition in a GUI, both of which have been recently investigated in HCI research. One is to reduce D. If, as soon as the system detects cursor motion, it helps by shifting the set of objects that is likely to include the target toward the approaching cursor, the numerator of Equation 1 drops. This is the solution investigated in the Drag-and-Pop technique [4]. Second, the system may expand whatever object is being approached by the cursor, thus increasing W and hence reducing the ID. With this solution, implemented in the Mac OS X Dock,1 performance can be facilitated even if the expansion is very late [14,17]."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Semantic pointing [5], a more recent treatment of the pointing facilitation problem, simultaneously attacks the numerator and the denominator of the D/W ratio. The display-control (DC) ratio linking cursor motion to mouse motion is made to depend on cursor position across the landscape of graphical objects: the default DC ratio being set to a high level, each object is surrounded by a ‘well’ of reduced DC ratio. Thus, while mouse amplitude is saved for large cursor motion toward objects (i.e., D is reduced), more amplitude is needed in the vicinity of the target (i.e., W increases). One attractive feature of semantic pointing is that, unlike previous attempts [4, 14], it facilitates performance without the cost of perturbing the visual display. The above solutions do have a potential for facilitating pointing, but they take it for granted that a screen cursor is a tool for pixel selection. Below we question this basic assumption."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Input Information Waste in Current GUIs"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"The present study was triggered by the observation that in current GUIs the amount of information received by the system is generally far less than that emitted by the mouse. Consider a graphical desktop with 40 icons, each 20x30 pixel (px) large, on a 1600x1200px screen. Selecting one of these icons means selecting 600px within a set of 1,920,000px, and this amounts to sending log2(1,920,000/600)=11.6 bits to the system. The system, however, just needs the specification of one icon among the 40 icons, that, log240=5.3 bits. So in this example, representative of many real HCI situations, the system will use hardly half of the information produced in pointing: a substantial proportion of the input information is wasted. This waste amounts quantitatively to log2(Ss/So) - log2N, with Ss denoting the surface area of the screen and So the surface area of the objects (assumed to be all the same size), and with N denoting the number of displayed objects."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Obviously, what is ignored by the system is unnecessary information. Consider the case in which the graphical desktop is entirely tiled with objects, leaving no empty spaces. In that limiting case, we have log2(Ss/So)=log2N. If, however, there are empty spaces, as is the case in many real displays, then the information emitted with the mouse will necessarily exceed that received by the system, and the larger the proportion of empty space in the display, the more bits wasted. So it is the information delivered by cursor motion through the voids of our graphical displays that the system (justly) ignores. Put differently, the continuous input from the hand contains a proportion of gratuitous information. As the cursor crosses an empty region of the display, the system keeps on updating the cursor position to reflect mouse motion. However, this is information just for the user— not to the system, which has to keep waiting for some discrete selection. The gratuitous component of pointing, we believe, lies in the fact that current GUIs force the user to select pixels whereas the system, more often than not, just needs the selection of discrete objects."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Our GUIs being based on bitmap graphics, let us call the current pointing mode bitmap pointing (BMP). Figure 1 shows what happens when the cursor moves to some object to select it. Time elapses along the figure’s horizontal axis. For the sake of simplicity, assume pointing to take place on a 1D desktop, and so space can be represented on the vertical axis. Suppose that the desktop displays two targets, which occupy intervals [AB] and [CD], and the cursor’s target is object [CD]. The starting point is O."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/OP1.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"At first, suppose the cursor is stationary. At time t0, when the cursor starts to move upwards, anyone—and hence the software that controls onscreen cursor motion—could safely guess that the user is starting a movement that will end up in either object [AB] or object [CD]: the only uncertainty left at t0 is target identity (1 bit, ignoring pointing abortion)."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"The system gains no information as the cursor crosses the empty space interval [OA]. At t1, when the cursor reaches the proximal boundary of the first object, this object gets highlighted (gray shading in the figure), signaling that if a click or an ENTER key press were to happen now, the system would activate that particular object. However, this is information from the system— not to the system. What is occurring at t1 was trivially predictable from t0 because [AB] had to be reached anyway, regardless of whether or not it was the movement’s target. The message emitted by the user over the [t0, t1] interval is essentially redundant."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"In fact, the single bit of information the system has been waiting for since t0 is delivered at time t2, when the cursor crosses the upper boundary of target [AB]: at that moment, the cursor is moving rather fast (i.e., the slope of the trajectory is steep), so there is no doubt that the cursor is leaving the object—the probability that the cursor aims at target [CD] switches to 1. Had its velocity been low and its acceleration negative (braking) at t2, one would have been able to guess that the target was interval [AB] with an overshoot. At any rate, the remainder of cursor motion from t2 to t4 will deliver no information whatsoever. Yet the standard BMP technology demands that users carefully finish up their movement, even though the final deceleration of a targeted movement is known to be the most costly phase, in terms of time and control effort [16]."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Object pointing"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"We now introduce what we call object pointing (OP). The OP mode involves an extra cursor, which we call the ‘timorous’ cursor (Tim) because it behaves on the screen as if it were ‘void’- phobic. Tim’s original feature is that it never visits empty regions of graphical space, thanks to an algorithm that uninterruptedly analyzes its kinematics. As soon as the algorithm detects that Tim has left an object, it identifies the current direction of Tim’s motion and makes it jump to the first object located in that direction. However, as long as Tim is within an object, it moves normally in parallel to the standard, continuous cursor. Note that in OP mode, the usual system cursor is ineffective for object selection: only Tim’s visit to objects can cause their highlight."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Object Pointing in 1D space"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Figure 2 illustrates OP in the case of the simple 1D pointing task of Figure 1. We suppose the user is initially in BMP mode. At time t0, with the standard, continuous cursor still at rest, the user switches to the OP mode. Tim could have popped up at the same location as the standard cursor, but because it is not within an object, it immediately jumps to the nearest boundary of the nearest object, causing this object to highlight. At t1, the mouse starts to move, causing the two cursors, now in different locations, to move upward in parallel, with Tim ‘safely’ within the object [AB]. At t2, Tim reaches point B, the upper boundary of the object, and hence jumps instantaneously to point C, the proximal boundary of object [CD], in which it can resume its continuous course parallel to the standard cursor. Note that when Tim reaches point D, the mouse is still pushing it upward (as revealed by the trajectory of the other cursor), but there is nothing beyond object [CD] and so Tim stays at D."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/OP2.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"This rather simple example in 1D space captures the main properties and potentialities of OP, which still hold in 2D or 3D space. One noteworthy property is that neither of the two screen cursors need to be shown to the user. Displaying the standard cursor in OP mode is superfluous because this cursor is ineffective. As for Tim, it is always in some object and that object is highlighted, so at every single instant the user receives the appropriate visual feedback, in the form of a highlight that jumps from object to object as the mouse moves."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"The main advantage of the OP mode is that it makes pointing work as though all the objects of the display had been packed together as a compact keyboard. Therefore distance as measured on the screen no longer constrains the ID. The only distance Tim actually needs to cover to reach its target is the sum of the widths of the obstacles it may have to cross. Obviously this distance depends on object density in the display, but it can only be shorter than D. Compare in Figures 1 and 2 the amplitudes covered by the continuous cursor, which in either mode faithfully reflects mouse movements. Second, if the target is the last object in the direction of the motion, OP makes pointing tolerance infinite in this direction. Thus, in Figure 2 the user slightly overshoots object [CD], but this error has no impact on target acquisition—after t3, Tim stays at the boundary of the object, which therefore remains highlighted."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Kinematic Conditions for the Jump. The algorithm we use for the control of Tim’s jumps in OP mode considers not only Tim’s current position, but also its instantaneous velocity and acceleration at the time it is found to leave an object. As soon as Tim is found to occupy a pixel that does not belong to some object, the algorithm evaluates whether two kinematic conditions are met. First, velocity must have reached a threshold: if not, Tim returns to the object’s boundary it has just left—so no jump will take place when Tim is just wandering in the vicinity of some object. Second, Tim’s current velocity must not be dropping too steeply: if Tim is decelerating while leaving an object, it returns to the boundary of the previous object—so no jump can take place in the case of a mere overshoot during object landing. If the above two kinematic conditions are met, then the algorithm starts to evaluate if a jump is in order."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Object Pointing in 2D Space"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"The basic features of OP are essentially the same in 1D, 2D and 3D spaces. Below, we focus on the 2D case, keeping in mind the importance of 2D displays in current GUIs. Identifying the Target Object. In 2D space the direction of Tim’s motion must be analyzed in angular terms. Provided the position, velocity and acceleration requirements are met, our algorithm performs a simple linear regression analysis using a small sample of xy coordinates from the recent history of Tim’s positions (e.g., the last five samples). Once the instantaneous direction of Tim’s motion has been identi-fied, the algorithm determines an angular sector centered around Tim’s current direction to search for a new object. If the search sector detects at least one object, Tim jumps to the proximal boundary of the nearest object. If the search is unsuccessful, the angular sector is incremented and the search starts again, up to a certain maximum angular sector. If the search fails to find any object in the largest angular sector, then Tim returns to its departure point. Eye movements. One argument for the workability of OP is the well-known behavioral fact that in pointing tasks the gaze precedes the hand. Typically, the target becomes the gaze fixation point before or at about the time the cursor starts to move [1,12]. This means that in OP mode, there should be no difficulty for the user to follow the jumping motion of the highlight across the layout of objects (regardless of whether or not Tim is visible): the user’s task will be to move the highlight from the periphery of the visual field to her/his current point of fixation."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Experiment 1: Reciprocal Pointing in 1D Space"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"The goal of Exp.1 was to quantitatively assess OP vs. BMP performance in a highly simplified laboratory task so designed as to allow a rigorous experimental control over a minimal number of relevant variables. We investigated three pointing conditions: the standard BMP mode (baseline) and two variants of the OP technique, one with the timorous cursor permanently visible (OPc) and the other with no cursor at all (the standard, continuous cursor was never displayed)."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Dependent Variables"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Movement time (MT), defined as the time elapsed between two correctly located clicks, was the main dependent variable. The other dependent variables were the amplitude of on-screen cursor motion, the amplitude of the hand movement, and the subjective rating of the difficulty of pointing in the various conditions."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Independent Variables"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/OP3.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Exp.1 was run in two parts (Table 1). Exp.1A served to manipulate Task difficulty by just varying W at a constant level of movement amplitude, with D set to a constant 800px, to avoid any experimental confound between the effects of difficulty and scale [10]. We used three levels of ID: 3.0, 5.5, and 8.1 bits (i.e., W=114, 18, and 3px, respectively)."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Exp.1B served to manipulate Task scale by varying D and W proportionally, so that the ID was a constant 3.46 bits (see Table 1). We used three levels of scale. For the lowest, D and W were set to 10 and 1px, respectively, creating a miniaturized task—the problematic feature was obviously W=1px, corresponding to 0.3mm on the tablet. For the next scale level, D and W were set to a comfortable 250 and 25px, corresponding on the tablet to 75 and 7.5mm, respectively. In the third condition, D and W were set to 1230 and 123px to force the puck to cover a rather large 367mm amplitude on the tablet. This extended scale range was expected to give rise, in the baseline BMP condition, to an optimum, V-shaped, relationship between MT and scale. Below, D identifies task scale (but recall that in Exp.1B W always equaled D/10)."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Since display-control gain was a constant 3.35px/mm in Exp.1, the scale manipulation of Exp.1B simultaneously affected display size and movement amplitude on the tablet (at least for BMP). We wished to evaluate OP in situations that capture the properties of real-world interfaces such as PDAs (resp. wall interfaces), which miniaturize (resp. magnify) both the display and the movement."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Hypotheses"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Three working hypotheses were derived for Exp.1 from our theoretical analysis of OP."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"1. Overall, pointing performance should be faster in OP mode than in standard BMP mode, thanks to the reduction of movement amplitude and—both targets of the reciprocal pointing paradigm being peripheral—the increase of target tolerance."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"2. In OP mode, the slope of Fitts’ law should be zero, because the variations of D and W are handled with immaterial time costs by the system. Since, in contrast, MT is known to follow Fitts’ law in the standard BMP mode, one predicts that the higher the ID, the larger the superiority of OP over BMP (Exp.1A)."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"3. In OP mode, MT should become scale-insensitive for the same reason as above. Since both interface miniaturization and magnification are known to impair BMP performance [3], the larger the deviation from optimal size in either direction, the larger the expected superiority of OP over BMP (Exp.1B)."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Method"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Equipment"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Exp. 1 was run on a PC running UNIX with a screen set to a 1600x1200 pixel resolution. The input device was a puck to be moved on an A3 Intuos 12x18’ Wacom tablet programmed in relative mode. Display and Task. We used Fitts’ (1954) classic 1D reciprocal-pointing paradigm [7]. The participants had to click back and forth on two dark-blue-colored vertical strips that extended from the top to the bottom of the screen, appearing in full-screen mode on a black background. The pointing movement had to be controlled exclusively along the left-right dimension. The target turned light-red when it was reached by the cursor, as if high-lighted—a necessary feature for the OP mode to work in the absence of any visible cursor. The cursor that controlled the highlight was a 1-pixel thick vertical line drawn in white from top to bottom. In the BMP condition the line cursor could be moved continuously across screen space. In contrast, in the two OP conditions the line cursor—which could be moved continuously within a target— could only jump from one target to the other. The cursor was displayed in the OPc condition but not in the OP condition. Note that a miss, being ineffective, had to be immediately corrected, simply resulting in an increased MT: error rate, a constant 0%, can be ignored."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Design and Procedure"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Exp.1A involved three pointing modes (BMP, OPc with Tim visible, and OP with Tim invisible) and three IDs, yielding a nine-cell withinparticipant experimental design, which we recycled in Exp.1B with scale replacing the ID (Table 1)."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Twelve unpaid volunteers participated in the experiment. However, due to errors in handling log files, we were left with a sample of 9 participants (Exp.1A) and 8 participants (Exp.1B) to assess the performances. Each participant ran two sets of 27 blocks of trials, the first set for Exp.1A and the second for Exp.1B. Each block comprised 10 movements, and so Exp.1 totaled 540 target acquisitions per participant. Within each set of 27 blocks, order effects were counterbalanced over conditions with Latin squares. The two sets, separated by a comfortable rest, made up a session that lasted approximately one and a half hour."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Results and Discussion"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Performance Speed"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/OP4.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Figure 3 shows mean MT as a function of task difficulty for each pointing condition."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"The variable on the x axis is the effective ID, IDe=log2(Ae/We +1), where Ae denotes effective amplitude (the average amplitude of cursor motion) and We denotes effective target width (the value of W which, given the observed dispersion of clicks, would have yielded 4% errors). Recourse to the IDe, computed on a participant-by-participant and block-by-block basis before averaging, makes it possible to assess Fitts’ law satisfactorily even if the correlation between movementendpoints dispersion and prescribed W is less than perfect [15]. Note, however, that this technique amounts to expressing Fitts’ law as a scatter plot linking two dependent measures, MT on the y axis and IDe on the x axis. Unlike the nominal (i.e., prescribed) value of ID, a systematic variable (i.e., a ‘factor’), IDe is a stochastic variable, which precludes the use of the analysis of variance to evaluate the impact of task difficulty. Note that the ID was computed identically for BMP and OP from onscreen length measurements."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Figure 3 shows that performance was always much faster for OP (mean MT=0.331s) than standard BMP (mean MT=1.274s), a 74% time-saving effect which the confidence limits show to be highly reliable. Second, whereas MT faithfully obeyed Fitts’ law for BMP (for the best-fitting equation, MT=0.246 IDe - 0.081), it no longer did for OP, where the mean slopes were 0 and - 0.01s/bit. Finally, Tim’s visibility had no incidence on OP performance."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/OP5.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Figure 4 shows mean MT as a function of task scale for each pointing condition, as measured in Exp.1B. Again, OP yielded considerably faster performance than BMP overall, the mean time saving amounting to 76% of MT."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Note the interaction between scale and pointing mode (p less than.0001): whereas for BMP performance speed was scale dependent, exhibiting the expected V-shaped relationship, for OP no scale effect was apparent. Newman-Keuls pair-wise comparisons revealed that for BMP both task miniaturization and task magnification significantly impaired performance (p<.05). For OP or OPc, in contrast, neither pair-wise difference approached significance. Tablet Amplitudes vs. Screen Distances. The data of Exp.1B, which contrasted very small and very large task scales on the screen, are well suited to illustrate the way in which the participants actually managed in tablet space to cover screen-space distances. Figure 5 shows, for the three pointing techniques, how the amplitude actually covered by the puck on the tablet varied with the distance separating the two targets on the screen. Although a slight scale effect was still observed with OP, the amplitude of the puck movement required in OP mode to handle the three levels of D remained very short, in comparison with the BMP mode, revealing a drastic input-device footprint reduction."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Subjective Difficulty Scores."}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"The rating, on a 5-point scale, of the difficulty experienced at pointing in Exp.1 was about the same for the two variants of OP (1.42 and 1.47). But pointing was judged far less difficult with the OP technique (mean SD=1.44 0.74) than the usual BMP technique (3.55 0.44). All but one participant (who equally scored OP and BMP), assigned a reduced score of difficulty to OP (sign test p<.001, one-tailed)."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/OP6.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Experiment 2: Serial Pointing in 2D Space"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"This experiment aimed at evaluating OP in 2D space, using a more realistic simulation of a GUI. Because the results of Exp.1 had confirmed that the visibility of Tim was superfluous, in Exp.2 the pointing-mode variable became binary, contrasting BMP vs. the variant of OP that never displays Tim. Pointing mode was crossed with another factor, onscreen target density, with the display exhibiting 6, 12, or 60 objects."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Methods"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Equipment and Display"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"The input device consisted of the same A3-format tablet as in Exp.1, but the puck was replaced by a standard mouse on which a stylus had been fixed. The mouse served to control onscreen cursor motion in relative mode, so that not only position, but also direction were defined in the ‘egocentric’ frame of reference of the hand. However, the attached stylus allowed the tablet to track the hand’s absolute position so as to allow footprint measurements. The screen resolution was set to 1024x768 pixels. The layout of the 6, 12, or 60 objects, all identical (32x32 pixel icons), was randomly drawn by the program on a black background. By default, the displayed objects were dark blue, but the object that was the current pointing target was shown in a more conspicuous lightgreen color. Highlighting of the currently visited object, whether light-green or dark-blue, was obtained by surrounding this object with a white outline that enlarged the object to 52x52 pixels."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Task"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["style","background-color: yellow;"]],"childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"The pointing paradigm was serial, but no longer reciprocal in the sense of a back and forth (stationary) movement. To track the green target, which every successful click made to jump to another unpredictably determined object, the participant had to produce a series of clicks to follow the path dictated by the program across graphical objects. This task was designed to mimic a rather common situation in GUIs (e.g., reaching and clicking the FILE menu, then the OPEN item, then browsing a tree, etc.). This also show that OP can apply to many types of widgets such as menus, buttons and icons. Within each display, 11 successive clicks had to be made, yielding blocks of 10 measurements of MT. If a target object was missed by the click, it remained the target, waiting for a correct click, and so a 0% error rate was imposed on all participants."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Participants and Procedure"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Twelve new unpaid volunteers participated. Each of the 6 cells of the design (2 modes x 3 object densities) was explored 6 times for each participant, yielding a set of 36 blocks each including 10 movements overall, with possible order effects being counterbalanced with Latin squares. The experiment was completed in a single session that lasted about 40 minutes."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Results and Discussion"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Performance Speed"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["align","CENTER"]],"childNodes":[{"nodeType":1,"tagName":"img","attributes":[["src","http://localhost:3000/assets/OP7.png"],["width",358],["height",326]]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Figure 6 shows the effect of movement difficulty on MT for BMP and OP. The two curves were computed by averaging the coefficients of Fitts’ law estimated in each participant. Above 3.6 bits (the abscissa of the intersection between the curves), the more difficult the task, the better OP relative to BMP."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"However, the curve intersection that specifies the critical level of difficulty above which OP began to surpass BMP depended on object density: the abscissa of this intersection (for the current version of our OP algorithm) was 2.7, 3.5, and 7.0 bits for the 6, 12, and 60 object condition, respectively. So, in keeping with our expectations, the less dense the display and the more difficult the task, the greater the benefit brought about by OP."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Mouse Footprint"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"We obtained an estimate of the mouse footprint for the BMP and the OP mode by computing on the x and y axis the SD of the absolute mouse coordinates delivered by the tablet. Since, with a normal spread of hand positions in both dimensions, a rectangle with its vertical and horizontal sides equal to 2 SD should include about 96% x 96% = 92% of all positions, mouse footprint can be estimated as the length of the rectangle’s diagonal, as SQRT(2 SDx + 2 SDy ), or as the rectangle’s surface area, as 2 SDx * 2 SDy. Even though this method can occasionally lead to overestimations of the foot print in case of a gross repositioning of the mouse, it ought not bias the OP vs. BMP footprint comparison. Using the rectangle’s diagonal, mouse footprint was 23.8% for OP relative to BMP (mean SD=37 0.6mm vs. 155 23mm). In terms of surface area, footprint in OP amounted to a minute 6.2% of BMP (695 234mm  vs. 11,192 3,191mm ). Satisfaction Scores. Overall, all three object densities mixed, OP and BMP scored about the same in terms of satisfaction concerning ease of use (12.8 vs. 12.3, respectively, t(11)=0.53, p>.1), but the scores depended on the density, in keeping with the speed data. No significant differences were found for the intermediate and higher density conditions. In the low-density condition, however, OP scored 15.8 and BMP 10.8 (t(11)=4.46, p less than .001, one tailed), with all individual judgments, save a tie, favoring OP over BMP."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Overview"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"To sum up, input flows in current GUIs suffer a serious waste of information because users are always asked to select pixels regardless of the fact that the system, more often than not, needs just the specification of a discrete object. We have introduced OP, a new pointing mode that dispenses the user of producing redundant cursor moves across the voids of graphical displays. With formal experiments in 1D and 2D space, we have shown that OP indeed facilitates target acquisition, both objectively and subjectively. The data corroborate our hypotheses that the benefit of OP increases (1) as pointing becomes more difficult—either because of a higher ID or because of a more marked departure, in either direction, from optimal interface size—and (2) as object density in graphical space decreases."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Implications for HCI Design"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"OP shares with semantic pointing [5] a valuable characteristic: it reduces the difficulty of target acquisition without perturbing the layout of graphical objects."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"However, the two techniques differ. Whereas semantic pointing affects the law’s intercept, with the whole curve being shifted downward, OP affects the slope of Fitts’ law, virtually canceling it. This means that, regardless of the spatial arrangement of objects in the display, OP makes pointing about as easy as though all objects were tightly packed together, thus forming a soft keyboard."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Since pointing is a basic building block of all our GUIs, the potential implementation scope of the OP mode seems to be fairly broad. Our demonstration that the advantage of OP over the current BMP technology is enhanced when pointing difficulty increases is obviously important—indeed, it is for difficult tasks that we need pointing optimization. Current trends in HCI technology raise two major challenges that seem tailored to the OP technique. First, with the spread, sooner or later, of highresolution screens, pointing difficulty will tend to increase in the future. The other challenge arises from the current broadening of the range of interface scale. Since interface scale is known to dramatically affect the bandwidth of the interaction [11], the OP technique seems particularly promising in the face of dramatically miniaturized and magnified displays."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"One spectacular characteristic of the OP mode is a considerable reduction of input device footprint. This feature may be useful for standard users, if only because desks are often cluttered, or touchpad area is limited. But it should be of special help to disabled users for whom the production of normal amplitude movements is a problem. OP makes it possible to control cursor motion in normal, zero-order mode (e.g., with a standard mouse) with strongly reduced hand moves."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"The OP technique is more than a mouse counterpart of the keyboard direction keys. One important difference is that the definition of the jumping direction with OP is far finer than up, down, left, and right, making it possible to move one’s selection, not simply through rows and columns, but through any arbitrary layout of objects. Moreover, unlike the set of direction keys on a keyboard, OP does not require a time consuming switch from one input device to another."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["style","background-color: yellow;"]],"childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Rather than an alternative to BMP, OP should be viewed as an optional mode made available to users beside the usual BMP mode. One should be allowed to switch opportunistically from BMP to OP, via some simple mouse command, to occasionally cope with pixels (e.g., in a drawing task). So the interface should provide the user with some convenient means to switch back and forth between OP and BMP."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["style","background-color: yellow;"]],"childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Obviously, OP does not yield any benefit for selection within display regions that are tiled with graphical objects, because such regions offer no voids. For example, following a horizontal path to reach the next hierarchical level in a cascading menu costs time [2], but for little or no gain: the probability that the cursor aims at the next (previous) level of the hierarchy when it starts moving to the right (left) is about 1. One solution is to make the menu highlight jump by discrete steps depending on the initial direction of cursor motion [13]. Facilitating pointing across tiled spaces with such a technique might nicely complement OP."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":1,"tagName":"strong","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Future Work"}]}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","attributes":[["style","background-color: yellow;"]],"childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"One problem that remains to be addressed is the design of an appropriate command to switch back and forth between OP and BMP. Among the possibilities, we may think of a combination of mouse-button presses or a brief oscillation of the cursor. The latter option seems particularly worth examining. Quick, small amplitude oscillations of the hand, very easy to produce [9], might usefully enrich the vocabulary of input commands."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"One possible development would be to also allow, in OP mode, the object highlight to switch from objects in the active window to objects hosted by surrounding windows, perhaps by setting different velocity thresholds for jumping within and between windows."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Our preliminary investigation used a newborn version of the OP algorithm for 2D space, with presumably suboptimal parameter settings. So, although OP already worked better than BMP, its efficiency can certainly be improved. One feature that will require special care is the setting of the initial value and the expansion dynamics of the angular sector that serves in OP mode to detect the target of current cursor motion."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n"},{"nodeType":1,"tagName":"p","childNodes":[{"nodeType":3,"nodeName":"#text","nodeValue":"Exp.2 is likely to have underestimated the performance benefit of OP, as novel techniques are inevitably penalized in evaluation experiments: OP was far less familiar to our participants than BMP. So more evaluation work is needed not only to optimize OP, but also to reevaluate the technique with practiced users."}]},{"nodeType":3,"nodeName":"#text","nodeValue":"\n\n\n"}]},"fileName":"objectPointing.html","index":1,"_id":"bEKDmlOax4nv1e9z"}
